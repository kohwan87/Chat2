{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT를 이용하여, Question_Answering 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT(Bi-directional Encoder Representations from Transformers)의 특징은 다음과 같이 생각할 수 있음\n",
    "\n",
    "1. BERT는 bi-directional Transformer로 이루어진 언어모델\n",
    "2. Multi head attention에서 encoder 부분의 12개 연결로 이루어짐\n",
    "3. Pre-Trained BERT 언어모델 위에 fine-tuning layer를 부착하여 다양한 NLP task를 수행 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 아래 코드는 미리 구글에서 공개한 Pre-trained Bert 모델 위에 새롭게 구성한 fine-tuning layer를 부착하여 Question_Answering task를 수행하고자 함.\n",
    "\n",
    "구글에서 미리 공개한 Pre-trained 모델은 다음과 같음\n",
    "\n",
    "https://github.com/google-research/bert 의 모델을 다운 받아 설치 후, 진행함\n",
    "\n",
    "\n",
    "BERT-Base 모델의 특징 : Multilingual Cased(104 languages), 12-layer, 768-hidden, 12-heads, 110M parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드는 직관적인 이해를 위해 Keras를 기반으로 구성되었으며, https://github.com/kimwoonggon 의 내용을 참고하였으며\n",
    "\n",
    "Data는 KorQuad v1.0을 기준으로 학습하였음.(https://korquad.github.io/dataset/KorQuAD_v1.0_train.json)\n",
    "\n",
    "전체적인 구성은 [데이터 전처리 - 사전 학습 모델 불러오기 - 파인튜닝 layer 구성하기 - 모델 학습 - 예측 하기] 순서로 구성되어 있음\n",
    "\n",
    "이제부터 시작합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행을 위한, bert의 사용을 쉽게 하기 위한 keras-bert, radam optimaizer 라이브러리 설치 및 import 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-bert\n",
    "#!pip install keras-radam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import Input, Model\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KorQuAD_v1.0의 train.json의 원활한 이용을 위해, pandas의 dataframe 형식으로 읽어옴.\n",
    "\n",
    "(실제 코드는 같은 폴더의 squad_json_to_dataframe.py를 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (60407, 6)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import squad_json_to_dataframe\n",
    "from squad_json_to_dataframe import squad_json_to_dataframe_train\n",
    "\n",
    "train = squad_json_to_dataframe_train(\"KorQuAD_v1.0_train.json\")\n",
    "\n",
    "# 60407개의 question, context, text(answer)로 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6566495-0-0</td>\n",
       "      <td>바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>교향곡</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6566495-0-1</td>\n",
       "      <td>바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>1악장</td>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6566495-0-2</td>\n",
       "      <td>바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>베토벤의 교향곡 9번</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6566518-0-0</td>\n",
       "      <td>1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6566518-0-1</td>\n",
       "      <td>파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>합창교향곡</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60402</th>\n",
       "      <td>6467478-1-1</td>\n",
       "      <td>뉴델리 메탈로 베타락마제가 처음 감염 된 지역은 어디인가?</td>\n",
       "      <td>유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (...</td>\n",
       "      <td>인도</td>\n",
       "      <td>73</td>\n",
       "      <td>9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60403</th>\n",
       "      <td>6467478-2-0</td>\n",
       "      <td>균은 유전자를 균에게 전달 할 수있는데 이러한 현상을 나타낸 용어는 무엇인가?</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>유전자 전달</td>\n",
       "      <td>253</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60404</th>\n",
       "      <td>6467478-2-1</td>\n",
       "      <td>박테리아가 NDM-1 유전자를 가지고 있을때 발생하는 전파를 분석하기위해 사용된 영...</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>37건</td>\n",
       "      <td>129</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60405</th>\n",
       "      <td>6490801-2-0</td>\n",
       "      <td>NDM-1 유전자를 가진 박테리아가 감수성을 보인 폴리믹슨 계열 항생제는?</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>콜리스틴</td>\n",
       "      <td>404</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60406</th>\n",
       "      <td>6490801-2-1</td>\n",
       "      <td>2010년 8월, NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석한 다국적 ...</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>The Lancet Infectious Diseases</td>\n",
       "      <td>13</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index                                           question  \\\n",
       "0      6566495-0-0                     바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?   \n",
       "1      6566495-0-1                      바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?   \n",
       "2      6566495-0-2                  바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?   \n",
       "3      6566518-0-0                     1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?   \n",
       "4      6566518-0-1                   파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?   \n",
       "...            ...                                                ...   \n",
       "60402  6467478-1-1                   뉴델리 메탈로 베타락마제가 처음 감염 된 지역은 어디인가?   \n",
       "60403  6467478-2-0        균은 유전자를 균에게 전달 할 수있는데 이러한 현상을 나타낸 용어는 무엇인가?   \n",
       "60404  6467478-2-1  박테리아가 NDM-1 유전자를 가지고 있을때 발생하는 전파를 분석하기위해 사용된 영...   \n",
       "60405  6490801-2-0         NDM-1 유전자를 가진 박테리아가 감수성을 보인 폴리믹슨 계열 항생제는?    \n",
       "60406  6490801-2-1  2010년 8월, NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석한 다국적 ...   \n",
       "\n",
       "                                                 context  \\\n",
       "0      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "1      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "2      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "3      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "4      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "...                                                  ...   \n",
       "60402  유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (...   \n",
       "60403  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60404  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60405  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60406  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "\n",
       "                                 text  answer_start  c_id  \n",
       "0                                 교향곡            54     0  \n",
       "1                                 1악장           421     0  \n",
       "2                         베토벤의 교향곡 9번           194     0  \n",
       "3                                파우스트            15     0  \n",
       "4                               합창교향곡           354     0  \n",
       "...                               ...           ...   ...  \n",
       "60402                              인도            73  9604  \n",
       "60403                          유전자 전달           253  9605  \n",
       "60404                             37건           129  9605  \n",
       "60405                            콜리스틴           404  9605  \n",
       "60406  The Lancet Infectious Diseases            13  9605  \n",
       "\n",
       "[60407 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 사용하는 몇 가지 변수들을 다음과 같이 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 384    # question, context의 토큰화된 sequence length는 토큰 개수 기준 최대 384개를 이용함. 일정 길이 이상이 되면 코랩에서 실행이 어려움\n",
    "BATCH_SIZE = 10  # Batch_size는 10\n",
    "EPOCHS=3         # 실제로 학습은 3회 진행하였으나, 실제 학습 할때는 1회 학습 후 저장, 1회 학습 후 저장, ... 함.\n",
    "LR=3e-5          # Learnning rate = 3e-5\n",
    "\n",
    "DATA_COLUMN = \"context\"                   #train 데이터의 context column\n",
    "QUESTION_COLUMN = \"question\"              #train 데이의 question column\n",
    "TEXT = \"text\"                             #train 데이터의 text(answer) column\n",
    "\n",
    "pretrained_path =\"bert\"                                               # 사전 학습 모델이 저장된 폴더\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')       # 사전 학습 모델의 여러 설정 사항\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')    # 사전 학습 모델\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')               # 사전 학습 모델 vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 학습 모델의 vocab을 이용하여 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        if \"_\" in token:\n",
    "            token = token.replace(\"_\",\"\")\n",
    "            token = \"##\" + token\n",
    "        token_dict[token] = len(token_dict)\n",
    "\n",
    "reverse_token_dict = {v : k for k, v in token_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 학습 모델의 단어장을 기반으로한 tokenizer 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inherit_Tokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        if not self._cased:\n",
    "            text = text\n",
    "            \n",
    "            text = text.lower()\n",
    "        spaced = ''\n",
    "        for ch in text:\n",
    "            if self._is_punctuation(ch) or self._is_cjk_character(ch):\n",
    "                spaced += ' ' + ch + ' '\n",
    "            elif self._is_space(ch):\n",
    "                spaced += ' '\n",
    "            elif ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\n",
    "                continue\n",
    "            else:\n",
    "                spaced += ch\n",
    "        tokens = []\n",
    "        for word in spaced.strip().split():\n",
    "            tokens += self._word_piece_tokenize(word)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = inherit_Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert 모형에 들어갈\n",
    "\n",
    "인풋은 Question과 Paragraph(Context)의 token으로 구성되어 있고, 아웃풋은 Paragraph(Context)에서의 시작 토큰과 끝나는 토큰의 순서로 구성되어 있음\n",
    "\n",
    "따라서 약 60,000개의 데이터의 인풋과 아웃풋을 이 과정으로 전처리 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3](img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특히, 인풋은 Token과 Segment(문장 구분, 여기서는 Question과 Paragraph를 각각 0,1로 구분함), Positional Embeddings 과정으로 이루어짐.\n",
    "\n",
    "Postional Embeddings 과정은 사전 학습 모델에 포함되어 있으므로, \n",
    "\n",
    "우리는 각 인풋 데이터를 토큰화 + Segment(문장구분)을 전처리 과정에 포함시켜 진행함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가? \n",
      "\n",
      "1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다. \n",
      "\n",
      "교향곡\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "question = train['question'][i]\n",
    "context = train['context'][i]\n",
    "text = train['text'][i]\n",
    "print(question,\"\\n\")\n",
    "print(context,\"\\n\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '바', '##그', '##너', '##는', '괴', '##테', '##의', '파', '##우스', '##트를', '읽', '##고', '무', '##엇', '##을', '쓰', '##고', '##자', '했', '##는', '##가', '?', '[SEP]', '1839', '##년', '바', '##그', '##너', '##는', '괴', '##테', '##의', '파', '##우스', '##트', '##을', '처음', '읽', '##고', '그', '내', '##용', '##에', '마', '##음', '##이', '끌', '##려', '이를', '소', '##재', '##로', '해', '##서', '하나의', '교', '##향', '##곡', '##을', '쓰', '##려', '##는', '뜻', '##을', '갖', '##는다', '.', '이', '시', '##기', '바', '##그', '##너', '##는', '1838', '##년에', '빛', '독', '##촉', '##으로', '산', '##전', '##수', '##전을', '다', '걲', '##은', '상', '##황', '##이', '##라', '좌', '##절', '##과', '실', '##망', '##에', '가', '##득', '##했으며', '메', '##피', '##스', '##토', '##펠', '##레스', '##를', '만', '##나는', '파', '##우스', '##트', '##의', '심', '##경', '##에', '공', '##감', '##했다', '##고', '한다', '.', '또한', '파', '##리에', '##서', '아', '##브', '##네', '##크', '##의', '지', '##휘', '##로', '파', '##리', '음악', '##원', '관', '##현', '##악', '##단', '##이', '연', '##주', '##하는', '베', '##토', '##벤', '##의', '교', '##향', '##곡', '9', '##번', '##을', '듣', '##고', '깊', '##은', '감', '##명을', '받', '##았', '##는데', ',', '이', '##것이', '이', '##듬', '##해', '1월', '##에', '파', '##우스', '##트', '##의', '서', '##곡', '##으로', '쓰', '##여', '##진', '이', '작', '##품', '##에', '조', '##금', '##이', '##라', '##도', '영향을', '끼', '##쳤', '##으', '##리', '##라는', '것은', '의', '##심', '##할', '여', '##지가', '없다', '.', '여', '##기의', '라', '##단', '##조', '조', '##성의', '경우', '##에도', '그의', '전', '##기에', '적', '##혀', '있는', '것', '##처럼', '단', '##순', '##한', '정', '##신', '##적', '피', '##로', '##나', '실', '##의', '##가', '반', '##영', '##된', '것이', '아니라', '베', '##토', '##벤', '##의', '합', '##창', '##교', '##향', '##곡', '조', '##성의', '영향을', '받은', '것을', '볼', '수', '있다', '.', '그', '##렇게', '교', '##향', '##곡', '작곡', '##을', '1839', '##년부터', '40', '##년에', '걸쳐', '파', '##리에', '##서', '착', '##수', '##했', '##으나', '1', '##악', '##장을', '쓴', '뒤', '##에', '중', '##단', '##했다', '.', '또한', '작', '##품', '##의', '완', '##성', '##과', '동시에', '그는', '이', '서', '##곡', '(', '1', '##악', '##장', ')', '을', '파', '##리', '음악', '##원의', '연', '##주', '##회', '##에서', '연', '##주', '##할', '파', '##트', '##보', '##까지', '준', '##비', '##하', '##였으나', ',', '실', '##제로', '##는', '이', '##루', '##어', '##지', '##지는', '않았다', '.', '결국', '초', '##연', '##은', '4', '##년', '반', '##이', '지', '##난', '후에', '드', '##레스', '##덴', '##에서', '연', '##주', '##되었고', '재', '##연', '##도', '이', '##루', '##어', '##졌', '##지만', ',', '이후', '##에', '그대로', '방', '##치', '##되고', '말', '##았다', '.', '그', '사이에', '그는', '리', '##엔', '##치', '##와', '방', '##황', '##하는', '네', '##덜', '##란드', '##인을', '완', '##성', '##하고', '탄', '##호', '##이', '##저', '##에도', '착', '##수', '##하는', '등', '분', '##주', '##한', '시', '##간을', '보', '##냈', '##는데', ',', '그', '##런', '바', '##쁜', '생', '##활', '##이', '이', '곡', '##을', '잊', '##게', '한', '것이', '아닌', '##가', '하는', '의', '##견', '##도', '있다', '.', '[SEP]'] \n",
      "\n",
      "['[CLS]', '교', '##향', '##곡', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(question, context),\"\\n\")\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " token ids :  [101, 9318, 78136, 70162, 11018, 8905, 119351, 10459, 9901, 89108, 101825, 9642, 11664, 9294, 119137, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 16221, 10954, 9318, 78136, 70162, 11018, 8905, 119351, 10459, 9901, 89108, 15184, 10622, 62849, 9642, 11664, 8924, 8996, 24974, 10530, 9246, 32158, 10739, 8973, 26737, 35756, 9448, 36210, 11261, 9960, 12424, 90387, 8907, 79544, 55670, 10622, 9511, 26737, 11018, 9153, 10622, 8854, 40410, 119, 9638, 9485, 12310, 9318, 78136, 70162, 11018, 16347, 27056, 9387, 9088, 119267, 11467, 9407, 16617, 15891, 54918, 9056, 100, 10892, 9414, 65649, 10739, 17342, 9686, 58931, 11882, 9489, 89292, 10530, 8843, 118813, 51491, 9272, 97146, 12605, 26444, 119394, 100929, 11513, 9248, 49742, 9901, 89108, 15184, 10459, 9491, 31720, 10530, 8896, 105197, 12490, 11664, 16139, 119, 19789, 9901, 46766, 12424, 9519, 52015, 77884, 20308, 10459, 9706, 119455, 11261, 9901, 12692, 74293, 14279, 8900, 30842, 119110, 24989, 10739, 9568, 16323, 12178, 9344, 26444, 118979, 10459, 8907, 79544, 55670, 130, 35465, 10622, 9116, 11664, 8938, 10892, 8848, 52859, 9322, 119118, 41850, 117, 9638, 97403, 9638, 118815, 14523, 17206, 10530, 9901, 89108, 15184, 10459, 9425, 55670, 11467, 9511, 29935, 18623, 9638, 9652, 52951, 10530, 9678, 40032, 10739, 17342, 12092, 58088, 8978, 119266, 119185, 12692, 60362, 30050, 9637, 71013, 14843, 9565, 80795, 39218, 119, 9565, 46874, 9157, 24989, 20626, 9678, 79599, 28467, 35979, 21555, 9665, 33797, 9664, 80579, 13767, 8870, 92383, 9059, 119064, 11102, 9670, 25387, 14801, 9946, 11261, 16439, 9489, 10459, 11287, 9321, 30858, 13441, 27487, 45021, 9344, 26444, 118979, 10459, 9957, 100420, 25242, 79544, 55670, 9678, 79599, 58088, 74141, 21371, 9359, 9460, 11506, 119, 8924, 82838, 8907, 79544, 55670, 76512, 10622, 16221, 87188, 10533, 27056, 92210, 9901, 46766, 12424, 9731, 15891, 119424, 35466, 122, 119110, 35963, 9512, 9109, 10530, 9694, 24989, 12490, 119, 19789, 9652, 52951, 10459, 9591, 17138, 11882, 58248, 17889, 9638, 9425, 55670, 113, 122, 119110, 13890, 114, 9633, 9901, 12692, 74293, 74125, 9568, 16323, 14863, 11489, 9568, 16323, 14843, 9901, 15184, 30005, 18382, 9691, 29455, 35506, 74519, 117, 9489, 53914, 11018, 9638, 35866, 12965, 12508, 32815, 49137, 119, 50342, 9757, 25486, 10892, 125, 10954, 9321, 10739, 9706, 33305, 56528, 9113, 100929, 118790, 11489, 9568, 16323, 49953, 9659, 25486, 12092, 9638, 35866, 12965, 119210, 28578, 117, 18347, 10530, 110589, 9328, 18622, 29208, 9251, 27303, 119, 8924, 64932, 17889, 9238, 86933, 18622, 12638, 9328, 65649, 12178, 9011, 118783, 61592, 83200, 9591, 17138, 12453, 9847, 20309, 10739, 48387, 35979, 9731, 15891, 12178, 9121, 9367, 16323, 11102, 9485, 90295, 9356, 118726, 41850, 117, 8924, 56710, 9318, 119023, 9420, 119446, 10739, 9638, 8889, 10622, 9649, 14153, 9954, 27487, 63783, 11287, 23969, 9637, 118634, 12092, 11506, 119, 102] \n",
      " segment :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "Aa, Bb= tokenizer.encode(question, context)\n",
    "print(\" token ids : \", Aa, \"\\n\",\"segment : \", Bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리를 60,000 라인에 적용하는 함수, 전처리 is all you need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    \n",
    "    global tokenizer\n",
    "    indices, segments, target_start, target_end = [], [], [], []\n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        \n",
    "        ids, segment = tokenizer.encode(data_df[QUESTION_COLUMN][i], data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
    "        \n",
    "\n",
    "        text = tokenizer.encode(data_df[TEXT][i])[0]\n",
    "\n",
    "        text_slide_len = len(text[1:-1])\n",
    "        for i in range(1,len(ids)-text_slide_len-1):  \n",
    "            exist_flag = 0\n",
    "            if text[1:-1] == ids[i:i+text_slide_len]:\n",
    "                ans_start = i\n",
    "                ans_end = i + text_slide_len - 1\n",
    "                exist_flag = 1\n",
    "                break\n",
    "        \n",
    "        if exist_flag == 0:\n",
    "            ans_start = SEQ_LEN\n",
    "            ans_end = SEQ_LEN\n",
    "\n",
    "        indices.append(ids)\n",
    "        segments.append(segment)\n",
    "\n",
    "        target_start.append(ans_start)\n",
    "        target_end.append(ans_end)\n",
    "\n",
    "    indices_x = np.array(indices)\n",
    "    segments = np.array(segments)\n",
    "    target_start = np.array(target_start)\n",
    "    target_end = np.array(target_end)\n",
    "    \n",
    "    del_list = np.where(target_start!=SEQ_LEN)[0]\n",
    "\n",
    "    indices_x = indices_x[del_list]\n",
    "    segments = segments[del_list]\n",
    "    target_start = target_start[del_list]\n",
    "    target_end = target_end[del_list]\n",
    "\n",
    "    train_y_0 = keras.utils.to_categorical(target_start, num_classes=SEQ_LEN, dtype='int64')\n",
    "    train_y_1 = keras.utils.to_categorical(target_end, num_classes=SEQ_LEN, dtype='int64')\n",
    "    train_y_cat = [train_y_0, train_y_1]\n",
    "    \n",
    "    return [indices_x, segments], train_y_cat\n",
    "\n",
    "def load_data(pandas_dataframe):\n",
    "    data_df = pandas_dataframe\n",
    "    \n",
    "    \n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_df[QUESTION_COLUMN] = data_df[QUESTION_COLUMN].astype(str)\n",
    "\n",
    "\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 60407/60407 [01:36<00:00, 628.09it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(train)\n",
    "# train_x = [ Question+Paraghraph Token, Segment ]\n",
    "# train_y = [ target_start, target_end ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   101,   9318,  78136, ...,  12178,   9011,    102],\n",
       "       [   101,   9318,  78136, ...,   9011, 118783,    102],\n",
       "       [   101,   9318,  78136, ...,   9011, 118783,    102],\n",
       "       ...,\n",
       "       [   101,   9319, 119351, ...,      0,      0,      0],\n",
       "       [   101,    182,  10162, ...,      0,      0,      0],\n",
       "       [   101,  19145,  17289, ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미리 다운로드 받은, pre-trained 모델을 불러온다.\n",
    "\n",
    "모델은 크게 transformers의 encoder 부분 12개로 구성되어 있으며, 인풋정보로 token과 segment를 받아 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 384, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 384, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 384, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 384, 768)     294912      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 384, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 384, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 384, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 384, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 384, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "==================================================================================================\n",
      "Total params: 177,164,544\n",
      "Trainable params: 177,164,544\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=False, trainable=True, seq_len=SEQ_LEN,)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 학습 모델위에 파인튜닝 된 모델을 얹을 준비를 한다.\n",
    "\n",
    "Korquad의 Answer는 정답을 위한 모든 토큰을 나타내 주는 것이 아닌, paragraph에 있는 정답의 첫번째 토큰의 위치와 마지막 토큰의 위치를 대답해준다.\n",
    "\n",
    "Keras의 장점인 모델 수정의 편리함을 적극 활용할 수 있다. 큰 방향은 다음과 같다.\n",
    "\n",
    "1. 마지막 encoder-12의 layer에서 나온 벡터의 전달을 위해, Masking 값을 True로 변환하는 layer\n",
    "2. Answer의 첫번째 Token을 예측하는 layer\n",
    "3. Answer의 마지막 Token을 예측하는 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonMasking(Layer):   \n",
    "    def __init__(self, **kwargs):   \n",
    "        self.supports_masking = True  \n",
    "        super(NonMasking, self).__init__(**kwargs)   \n",
    "  \n",
    "    def build(self, input_shape):   \n",
    "        input_shape = input_shape   \n",
    "  \n",
    "    def compute_mask(self, input, input_mask=None):   \n",
    "        return None   \n",
    "  \n",
    "    def call(self, x, mask=None):   \n",
    "        return x   \n",
    "  \n",
    "    def get_output_shape_for(self, input_shape):   \n",
    "        return input_shape\n",
    "    \n",
    "class MyLayer_Start(Layer):\n",
    "\n",
    "    def __init__(self,seq_len, **kwargs):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.supports_masking = True\n",
    "        super(MyLayer_Start, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                 shape=(input_shape[2],2),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(MyLayer_Start, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        x = K.reshape(x, shape=(-1,self.seq_len,K.shape(x)[2]))\n",
    "        x = K.dot(x, self.W)\n",
    "        \n",
    "        x = K.permute_dimensions(x, (2,0,1))\n",
    "\n",
    "        self.start_logits, self.end_logits = x[0], x[1]\n",
    "        \n",
    "        self.start_logits = K.softmax(self.start_logits, axis=-1)\n",
    "        \n",
    "        return self.start_logits\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.seq_len)\n",
    "\n",
    "\n",
    "class MyLayer_End(Layer):\n",
    "    \n",
    "    def __init__(self,seq_len, **kwargs):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.supports_masking = True\n",
    "        super(MyLayer_End, self).__init__(**kwargs)\n",
    "  \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                 shape=(input_shape[2], 2),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(MyLayer_End, self).build(input_shape)\n",
    "\n",
    "  \n",
    "    def call(self, x):\n",
    "\n",
    "        \n",
    "        x = K.reshape(x, shape=(-1,self.seq_len,K.shape(x)[2]))\n",
    "        x = K.dot(x, self.W)\n",
    "        x = K.permute_dimensions(x, (2,0,1))\n",
    "        \n",
    "        self.start_logits, self.end_logits = x[0], x[1]\n",
    "        \n",
    "        self.end_logits = K.softmax(self.end_logits, axis=-1)\n",
    "        \n",
    "        return self.end_logits\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 사전 학습 모델에 layer 3개를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import merge, dot, concatenate\n",
    "from keras import metrics\n",
    "\n",
    "def get_bert_finetuning_model(model):\n",
    "    \n",
    "    inputs = model.inputs[:2]\n",
    "    dense = model.output\n",
    "    x = NonMasking()(dense)\n",
    "    outputs_start = MyLayer_Start(SEQ_LEN)(x)\n",
    "    outputs_end = MyLayer_End(SEQ_LEN)(x)\n",
    "    bert_model = keras.models.Model(inputs, [outputs_start, outputs_end])\n",
    "    bert_model.compile(\n",
    "        optimizer=RAdam(learning_rate=LR, decay=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "  \n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 384, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 384, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 384, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 384, 768)     294912      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 384, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 384, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 384, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 384, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 384, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "non_masking_13 (NonMasking)     (None, 384, 768)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "my_layer__start_10 (MyLayer_Sta (None, 384)          1536        non_masking_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "my_layer__end_8 (MyLayer_End)   (None, 384)          1536        non_masking_13[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 177,167,616\n",
      "Trainable params: 177,167,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model = get_bert_finetuning_model(model)\n",
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습... colab에서 GPU로 돌리더라도 엄청나게 오래걸리며, 모델을 저장한 용량도(약 700MB) 매우 크다...\n",
    "\n",
    "혹시나 개인 PC에서 실행시키지 않길 바란다. 우리는 미리 학습된 모델을 Load할 예정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행은 필수로 colab에서... GPU를 사용하면 epochs =1 당 4~5시간 정도 소요.\n",
    "# 연달아서 실행하면 자주 error가 뜨는 모습이 나타나기도 함. 1 epoch 실행 후, save, load 를 반복하는 방식으로 진행\n",
    "# bert_model.fit(train_x, train_y, batch_size=10, validation_split=0.05, shuffle=False, verbose=1)\n",
    "# bert_model.save_weights(\"korquad_1.h5\")\n",
    "# bert_model.compile(optimizer=RAdam(learning_rate=0.00003, decay=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# bert_model.fit(train_x, train_y, batch_size=10, shuffle=False, verbose=1)\n",
    "# bert_model.save_weights(\"korquad_2.h5\")\n",
    "# bert_model.compile(optimizer=RAdam(learning_rate=0.00001, decay=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# bert_model.save_weights(\"korquad_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = get_bert_finetuning_model(model)\n",
    "bert_model.load_weights(\"korquad_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모든 준비가 끝났다. 학습한 모델을 토대로 Question, Answering을 예측하는 함수를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question과 paragraph를 받아서, token, segment를 만든다.\n",
    "\n",
    "def convert_pred_data(question, doc):\n",
    "    global tokenizer\n",
    "    indices, segments = [], []\n",
    "    ids, segment = tokenizer.encode(question, doc, max_len=SEQ_LEN)\n",
    "    indices.append(ids)\n",
    "    segments.append(segment)\n",
    "    indices_x = np.array(indices)\n",
    "    segments = np.array(segments)\n",
    "    return [indices_x, segments]\n",
    "\n",
    "def load_pred_data(question, doc):\n",
    "    data_x = convert_pred_data(question, doc)\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_letter(question, doc):\n",
    "  \n",
    "    test_input = load_pred_data(question, doc)             # question과 paragraph를 token,segment로 변수에 저장\n",
    "    test_start, test_end = bert_model.predict(test_input)  # 학습 모델에 넣고 answer의 start와 end token 예측   \n",
    "  \n",
    "    indexes = tokenizer.encode(question, doc, max_len=SEQ_LEN)[0] \n",
    "    start = np.argmax(test_start, axis=1).item()      # 예측한 start_token의 위치 \n",
    "    end = np.argmax(test_end, axis=1).item()          # 예측한 end_token의 위치\n",
    "    start_tok = indexes[start]                        # 예측한 start_token\n",
    "    end_tok = indexes[end]                            # 예측한 end_token\n",
    "    print(\"질문 : \", question)\n",
    "  \n",
    "    print(\"-\"*70)\n",
    "    print(\"텍스트 : \", end = \" \")\n",
    "  \n",
    "    def split_text(text, n):                                  # context 줄바꾸기\n",
    "        for line in text.splitlines():\n",
    "            while len(line) > n:\n",
    "                x, line = line[:n], line[n:]\n",
    "                yield x\n",
    "            yield line\n",
    "\n",
    "    for line in split_text(doc, 70):\n",
    "        print(line)\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    print(\"예측한 정답(토큰) : \", end = \" \")\n",
    "    print(\"\\n\")\n",
    "    sentences = []\n",
    "  \n",
    "    for i in range(start, end+1):\n",
    "        token_based_word = reverse_token_dict[indexes[i]]\n",
    "        sentences.append(token_based_word)\n",
    "        print(token_based_word, end= \" \")                   # 예측한 정답, start와 end 토큰 사이의 모든 토큰을 보여줌\n",
    "  \n",
    "    print(\"\\n\")\n",
    "    print(\"예측한 정답 : \", end = \"\")\n",
    "    for w in sentences:\n",
    "        if w.startswith(\"##\"):\n",
    "            w = w.replace(\"##\", \"\")\n",
    "        else:\n",
    "            w = \" \" + w                                 # 예측한 정답의 ##를 제외하고 보여준다.\n",
    "      \n",
    "        print(w, end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 :  수학자는 누구인가?\n",
      "----------------------------------------------------------------------\n",
      "텍스트 :  고대 그리스 수학자는 플라톤이다.\n",
      "----------------------------------------------------------------------\n",
      "예측한 정답(토큰) :  \n",
      "\n",
      "플 ##라 ##톤 \n",
      "\n",
      "예측한 정답 :  플라톤\n"
     ]
    }
   ],
   "source": [
    "doc = '고대 그리스 수학자는 플라톤이다.'\n",
    "question = \"수학자는 누구인가?\"\n",
    "\n",
    "predict_letter(question, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_score(question, doc, sign):\n",
    "    \n",
    "    import matplotlib\n",
    "    from matplotlib import font_manager, rc\n",
    "    import platform\n",
    "    import seaborn as sns\n",
    "\n",
    "    if platform.system() == 'Windows':\n",
    "        # 윈도우인 경우\n",
    "        font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "        rc('font', family=font_name)\n",
    "    else:    \n",
    "        # Mac 인 경우\n",
    "        rc('font', family='AppleGothic')\n",
    "        \n",
    "    matplotlib.pyplot.title('Token_scores')\n",
    "    \n",
    "    # Use plot styling from seaborn.\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "    # Increase the plot size and font size.\n",
    "    # sns.set(font_scale=1.5)\n",
    "    matplotlib.pyplot.rcParams[\"figure.figsize\"] = (16,8)\n",
    "\n",
    "    test_input = load_pred_data(question, doc)             # question과 paragraph를 token,segment로 변수에 저장\n",
    "    test_start, test_end = bert_model.predict(test_input)  # 학습 모델에 넣고 answer의 start와 end token 예측   \n",
    "    \n",
    "    s_scores = test_start\n",
    "    #print(s_scores[0])\n",
    "    e_scores = test_end\n",
    "\n",
    "    indexes = tokenizer.encode(question, doc, max_len=SEQ_LEN)[0] \n",
    "    #print(indexes)\n",
    "    \n",
    "    sentences = []\n",
    "    for i in range(0, SEQ_LEN):\n",
    "        token_based_word = reverse_token_dict[indexes[i]]\n",
    "        sentences.append(token_based_word)\n",
    "    \n",
    "    # Create a barplot showing the start word score for all of the tokens.\n",
    "    if sign == \"start\":\n",
    "        ax = sns.barplot(x=sentences[1:], y=s_scores[0][1:], ci=None)    \n",
    "    else:\n",
    "        ax = sns.barplot(x=sentences[1:], y=e_scores[0][1:], ci=None)\n",
    "    # Turn the xlabels vertical.\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "\n",
    "    # Turn on the vertical grid to help align words to scores.\n",
    "    ax.grid(True)\n",
    "\n",
    "    matplotlib.pyplot.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 :  바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "----------------------------------------------------------------------\n",
      "텍스트 :  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다.\n",
      "----------------------------------------------------------------------\n",
      "예측한 정답(토큰) :  \n",
      "\n",
      "교 ##향 ##곡 \n",
      "\n",
      "예측한 정답 :  교향곡\n"
     ]
    }
   ],
   "source": [
    "question = \"바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\"\n",
    "\n",
    "doc=\"1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다.\" \n",
    "\n",
    "predict_letter(question, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Token의 예측 : \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Start Token의 예측 : \")\n",
    "token_score(question, doc, \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Token의 예측 : \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"End Token의 예측 : \")\n",
    "token_score(question, doc, \"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
